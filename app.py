#!/usr/bin/env python3
"""
GraphRAG Agent ä¸»åº”ç”¨å…¥å£
ç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…å¤æ‚çš„æ¨¡å—å¯¼å…¥é—®é¢˜
"""

import os
import sys
from pathlib import Path
import openai
import PyPDF2
import io

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "server"))

from fastapi import FastAPI, HTTPException, File, UploadFile
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="GraphRAG Agent API",
    description="åŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½æ–‡æ¡£åˆ†æç³»ç»Ÿ",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰åŸŸå
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰HTTPæ–¹æ³•
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {"message": "GraphRAG Agent API is running!", "version": "1.0.0"}

@app.get("/api/graphrag/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "service": "GraphRAG Agent",
        "database": "memory" if os.getenv("DATABASE_TYPE", "memory") == "memory" else "neo4j",
        "embedding_provider": os.getenv("CACHE_EMBEDDING_PROVIDER", "openai")
    }

def extract_text_from_file(content: bytes, filename: str) -> str:
    """ä»æ–‡ä»¶å†…å®¹æå–æ–‡æœ¬"""
    try:
        if filename.lower().endswith('.pdf'):
            # PDFæ–‡ä»¶æå–
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(content))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text.strip()
        elif filename.lower().endswith(('.txt', '.md')):
            # æ–‡æœ¬æ–‡ä»¶
            return content.decode('utf-8', errors='ignore')
        else:
            # å…¶ä»–æ–‡ä»¶ç±»å‹ï¼Œå°è¯•è§£ç ä¸ºæ–‡æœ¬
            return content.decode('utf-8', errors='ignore')
    except Exception as e:
        print(f"æ–‡ä»¶å†…å®¹æå–å¤±è´¥: {e}")
        return f"æ— æ³•æå–æ–‡ä»¶å†…å®¹ï¼Œæ–‡ä»¶ç±»å‹: {filename.split('.')[-1] if '.' in filename else 'unknown'}"

async def analyze_with_openai(text_content: str, filename: str) -> dict:
    """ä½¿ç”¨OpenAIè¿›è¡ŒçœŸæ­£çš„AIå†…å®¹åˆ†æ"""
    try:
        # è®¾ç½®OpenAI API key
        openai.api_key = os.getenv('OPENAI_API_KEY')
        
        # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…tokenè¶…é™
        if len(text_content) > 8000:
            text_content = text_content[:8000] + "..."
            
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š

æ–‡æ¡£åç§°: {filename}
æ–‡æ¡£å†…å®¹:
{text_content}

è¯·è¿”å›ä»¥ä¸‹æ ¼å¼çš„JSONï¼š
{{
    "content": "æ–‡æ¡£å†…å®¹çš„è¯¦ç»†æ‘˜è¦(150å­—ä»¥å†…)",
    "concepts": ["æå–çš„å…³é”®æ¦‚å¿µ1", "æ¦‚å¿µ2", "æ¦‚å¿µ3", "æ¦‚å¿µ4"],
    "entities": ["é‡è¦å®ä½“1", "å®ä½“2", "å®ä½“3", "å®ä½“4"],
    "knowledgeTreeSuggestion": "å»ºè®®çš„çŸ¥è¯†æ ‘åˆ†ç±»è·¯å¾„(å¦‚:æŠ€æœ¯æ–‡æ¡£/AIå¼€å‘/ç³»ç»Ÿæ¶æ„)",
    "confidence": 0.9
}}

æ³¨æ„ï¼š
1. è¯·åŸºäºæ–‡æ¡£çš„å®é™…å†…å®¹è¿›è¡Œåˆ†æï¼Œä¸è¦åªä¾èµ–æ–‡ä»¶å
2. æ¦‚å¿µå’Œå®ä½“è¦ä»æ–‡æ¡£å†…å®¹ä¸­çœŸå®æå–
3. çŸ¥è¯†æ ‘å»ºè®®è¦å‡†ç¡®åæ˜ æ–‡æ¡£çš„ä¸»é¢˜åˆ†ç±»
4. ç½®ä¿¡åº¦ä¸º0-1ä¹‹é—´çš„æ•°å­—
"""

        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æå–æ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹ã€æ¦‚å¿µå’Œå®ä½“ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=800
        )
        
        result_text = response.choices[0].message.content
        print(f"ğŸ¤– OpenAIåˆ†æç»“æœ: {result_text}")
        
        # è§£æJSONå“åº”
        import json
        result = json.loads(result_text)
        return result
        
    except Exception as e:
        print(f"âŒ OpenAIåˆ†æå¤±è´¥: {e}")
        # å›é€€åˆ°åŸºç¡€åˆ†æ
        return {
            "content": f"åŸºäºAIåˆ†æçš„æ–‡æ¡£æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œæ–‡æ¡£åç§°ï¼š{filename}",
            "concepts": ["æ–‡æ¡£åˆ†æ", "å†…å®¹æå–"],
            "entities": ["AIç³»ç»Ÿ", "ç”¨æˆ·"],
            "knowledgeTreeSuggestion": "æ–‡æ¡£ç®¡ç†/AIåˆ†æ/å¾…å¤„ç†",
            "confidence": 0.6
        }

@app.post("/api/graphrag/analyze")
async def analyze_document(file: UploadFile = File(...)):
    """çœŸæ­£çš„AIæ–‡æ¡£åˆ†æç«¯ç‚¹"""
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        filename = file.filename
        file_size = len(content)
        
        print(f"ğŸ“„ æ¥æ”¶åˆ°æ–‡ä»¶: {filename}, å¤§å°: {file_size} bytes")
        
        # ğŸ”¥ æå–æ–‡ä»¶æ–‡æœ¬å†…å®¹
        text_content = extract_text_from_file(content, filename)
        print(f"ğŸ“ æå–æ–‡æœ¬é•¿åº¦: {len(text_content)} å­—ç¬¦")
        
        # ğŸ¤– ä½¿ç”¨OpenAIè¿›è¡ŒçœŸæ­£çš„AIåˆ†æ
        if text_content and len(text_content) > 50:  # ç¡®ä¿æœ‰è¶³å¤Ÿå†…å®¹åˆ†æ
            ai_analysis = await analyze_with_openai(text_content, filename)
        else:
            # å¦‚æœå†…å®¹å¤ªå°‘ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ
            ai_analysis = {
                "content": f"æ–‡æ¡£å†…å®¹è¾ƒå°‘æˆ–æ— æ³•æå–ï¼Œæ–‡ä»¶åï¼š{filename}",
                "concepts": ["æ–‡æ¡£å¤„ç†", "å†…å®¹æå–"],
                "entities": ["æ–‡æ¡£", "ç³»ç»Ÿ"],
                "knowledgeTreeSuggestion": "æ–‡æ¡£ç®¡ç†/å¾…åˆ†ç±»/éœ€è¦å¤„ç†",
                "confidence": 0.5
            }
        
        return {
            "status": "success",
            "analysis": {
                "content": ai_analysis.get("content", "AIåˆ†æå®Œæˆ"),
                "concepts": ai_analysis.get("concepts", []),
                "entities": ai_analysis.get("entities", []),
                "knowledgeTreeSuggestion": ai_analysis.get("knowledgeTreeSuggestion", "æ–‡æ¡£ç®¡ç†/AIåˆ†æ"),
                "confidence": ai_analysis.get("confidence", 0.85),
                "fileInfo": {
                    "filename": filename,
                    "size": file_size,
                    "type": file.content_type or "unknown",
                    "textLength": len(text_content) if 'text_content' in locals() else 0
                }
            },
            "service_ready": True
        }
    except Exception as e:
        print(f"âŒ åˆ†æé”™è¯¯: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"åˆ†æå¤±è´¥: {str(e)}",
                "service_ready": False
            }
        )

@app.post("/api/chat")
async def chat():
    """å¯¹è¯ç«¯ç‚¹"""
    try:
        return {
            "status": "success", 
            "response": "GraphRAGæ™ºèƒ½å¯¹è¯åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼",
            "service_ready": True
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"å¯¹è¯å¤±è´¥: {str(e)}",
                "service_ready": False
            }
        )

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    print(f"ğŸš€ å¯åŠ¨GraphRAG Agent (ç®€åŒ–ç‰ˆ)...")
    print(f"ğŸ“¡ ç«¯å£: {port}")
    
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=port,
        log_level="info"
    )